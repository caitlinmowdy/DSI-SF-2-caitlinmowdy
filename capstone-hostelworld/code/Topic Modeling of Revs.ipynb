{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling of Revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from gensim import corpora, models, matutils\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21675, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rev_date</th>\n",
       "      <th>score</th>\n",
       "      <th>hostel</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>excellent value</td>\n",
       "      <td>1189474</td>\n",
       "      <td>30th Jun 2004</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Fortuna Botel</td>\n",
       "      <td>Budapest, Hungary</td>\n",
       "      <td>http://www.hostelworld.com/hosteldetails.php/F...</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>i had a great time there because of the beach ...</td>\n",
       "      <td>1595059</td>\n",
       "      <td>23rd Dec 2004</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Equity Point Sea</td>\n",
       "      <td>Barcelona, Spain</td>\n",
       "      <td>http://www.hostelworld.com/hosteldetails.php/E...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "\n",
       "                                                text  user_id        rev_date  \\\n",
       "0                                    excellent value  1189474   30th Jun 2004   \n",
       "1  i had a great time there because of the beach ...  1595059   23rd Dec 2004   \n",
       "\n",
       "   score            hostel           location  \\\n",
       "0    7.7     Fortuna Botel  Budapest, Hungary   \n",
       "1    7.7  Equity Point Sea   Barcelona, Spain   \n",
       "\n",
       "                                                link   country       city  \\\n",
       "0  http://www.hostelworld.com/hosteldetails.php/F...   Hungary   Budapest   \n",
       "1  http://www.hostelworld.com/hosteldetails.php/E...     Spain  Barcelona   \n",
       "\n",
       "   day  month  year  \n",
       "0   30      6  2004  \n",
       "1   23     12  2004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import clean revs data\n",
    "\n",
    "revs_df = pd.read_csv('/Users/caitlinmowdy/Desktop/DSI-SF-2-caitlinmowdy/capstone-hostelworld/clean-data/clean_revs_en_oct5.csv')\n",
    "display(revs_df.shape, revs_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=2500,binary=True)#max_features=2500\n",
    "words = cv.fit_transform(revs_df.text).todense()\n",
    "\n",
    "words = pd.DataFrame(words, columns=cv.get_feature_names())\n",
    "\n",
    "# words.groupby(words.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are words I've decided to add to my stop words through a process of trial and error\n",
    "\n",
    "stop_wrds = ['hostel','hostels','customer','ive','comment','nice','place','did','10','min', 'youre',\n",
    "             'minutes','friendly','bit','minute','think','know','im','sure','great','temple','nights',\n",
    "             'really','stayed','hotel','like','just','didnt','id','ok','stay','dont','ve','light','red',\n",
    "             'wasnt','definitely','best','good','didn','don']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a list my_stop_words with english stop words and new stop words\n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(stop_wrds) #,stop_noise, stop_nums, stop_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2), max_features=2500, binary=True, \n",
    "                             stop_words=my_stop_words, min_df=.00008, max_df=.005)\n",
    "\n",
    "X = vectorizer.fit_transform(revs_df.text).todense()\n",
    "\n",
    "vocab2 = {v: k for k, v in vectorizer.vocabulary_.iteritems()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.001*helpful arrived + 0.001*toilets dirty + 0.001*speaks english + 0.001*new friends + 0.001*street walk'),\n",
       " (1,\n",
       "  u'0.001*staff attentive + 0.001*hard sleep + 0.001*went way + 0.001*straight away + 0.001*shower toilet'),\n",
       " (2,\n",
       "  u'0.001*central location + 0.001*bed shower + 0.001*showers floor + 0.001*water room + 0.001*extra mile'),\n",
       " (3,\n",
       "  u'0.001*room locked + 0.001*hope soon + 0.001*station short + 0.001*kitchen location + 0.001*rooms lot'),\n",
       " (4,\n",
       "  u'0.001*party night + 0.001*extremely noisy + 0.001*room rooms + 0.001*answer questions + 0.001*bathrooms cleaned'),\n",
       " (5,\n",
       "  u'0.001*restaurant bar + 0.001*helpful pleasant + 0.001*loved staying + 0.001*clean free + 0.001*atmosphere quiet'),\n",
       " (6,\n",
       "  u'0.001*wait long + 0.001*helpful feel + 0.001*fantastic helpful + 0.001*quite clean + 0.001*rooms way'),\n",
       " (7,\n",
       "  u'0.001*night long + 0.001*couple days + 0.001*old house + 0.001*breakfast amazing + 0.001*downside location'),\n",
       " (8,\n",
       "  u'0.001*night staff + 0.001*credit card + 0.001*room lock + 0.001*bar closed + 0.001*near termini'),\n",
       " (9,\n",
       "  u'0.001*modern clean + 0.001*vibe staff + 0.001*rooms people + 0.001*night bus + 0.001*cold showers')]"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2 = models.LdaModel(\n",
    "    num_topics  =  10,\n",
    "    passes      =  2,\n",
    "    id2word     =  vocab2\n",
    "    )\n",
    "\n",
    "lda2.print_topics(num_topics=10, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow = []\n",
    "blank_documents = 0\n",
    "\n",
    "for document in X.tolist():\n",
    "\n",
    "    single_document = []\n",
    "\n",
    "    for token_id, token_count in enumerate(document):\n",
    "        \n",
    "        if token_count > 0:\n",
    "              single_document.append((token_id, token_count))\n",
    "            \n",
    "    if len(single_document)>0:\n",
    "        bow.append(single_document)\n",
    "    else:\n",
    "        blank_documents += 1\n",
    "        bow.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe of probabilites by topics \n",
    "\n",
    "topic_proba =lda2.get_document_topics(bow)\n",
    "\n",
    "simplelist =[]\n",
    "for x in topic_proba:\n",
    "    simplelist.append(x)\n",
    "\n",
    "# list of lists , inner list, each one should be only 10 (topic numbers) values (non-tuples)\n",
    "valuelist = [[y[1] for y in line] for line in simplelist]\n",
    "\n",
    "topicdf_nomax = pd.DataFrame(valuelist, columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21675, 10)"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicdf_nomax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new columns to topic porb dataframe for the sum of topic prob and max topic probabitliyt for every document\n",
    "\n",
    "columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
    "topicdf_nomax['sum_prob'] =  topicdf_nomax[columns].apply(np.sum, axis=1)\n",
    "topicdf_nomax['max_prob'] =  topicdf_nomax[columns].apply(np.max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21675.000000\n",
       "mean         0.471411\n",
       "std          0.320506\n",
       "min          0.100000\n",
       "25%          0.100000\n",
       "50%          0.549836\n",
       "75%          0.774930\n",
       "max          0.957131\n",
       "Name: max_prob, dtype: float64"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicdf_nomax['max_prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a154090>"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAECCAYAAAAYfWtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a18ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hist of max topic prob for each document in revs_df\n",
    "topicdf_nomax['max_prob'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "doc_topics = [lda2.get_document_topics(doc) for doc in bow]\n",
    "\n",
    "doc_topic_probabilities = []\n",
    "\n",
    "for document in doc_topics:\n",
    "    \n",
    "    single_document = []\n",
    "    \n",
    "    for topic, probablity in document:\n",
    "        \n",
    "        single_document.append(probablity)\n",
    "        \n",
    "    doc_topic_probabilities.append(single_document)\n",
    "    \n",
    "docs_topics = pd.DataFrame(doc_topic_probabilities)\n",
    "sns.heatmap(docs_topics)\n",
    "\n",
    "# doc_topics\n",
    "# doc_topic_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054524</td>\n",
       "      <td>0.051940</td>\n",
       "      <td>0.847221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.414784</td>\n",
       "      <td>0.470216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.286892</td>\n",
       "      <td>0.186649</td>\n",
       "      <td>0.089549</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.270040</td>\n",
       "      <td>0.047412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333  0.013333   \n",
       "1  0.054524  0.051940  0.847221       NaN       NaN       NaN       NaN   \n",
       "2  0.020000  0.020000  0.020000  0.020000  0.020000  0.020000  0.020000   \n",
       "3  0.414784  0.470216       NaN       NaN       NaN       NaN       NaN   \n",
       "4  0.286892  0.186649  0.089549  0.037387  0.054380  0.270040  0.047412   \n",
       "\n",
       "         7         8         9     ...           15        16        17  \\\n",
       "0  0.013333  0.013333  0.346667    ...     0.013333  0.013333  0.013333   \n",
       "1       NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "2  0.020000  0.020000  0.020000    ...     0.020000  0.020000  0.020000   \n",
       "3       NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "\n",
       "         18        19        20        21        22        23        24  \n",
       "0  0.013333  0.013333  0.013333  0.346667  0.013333  0.013333  0.013333  \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2  0.020000  0.020000  0.020000  0.520000  0.020000  0.020000  0.020000  \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# revs_words = revs_clean_df + top_words\n",
    "rev_w_words = pd.concat([revs_clean_df, top_words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#                                old Work \n",
    "\n",
    "# find most commor words in revs from like df \n",
    "\n",
    "cv_like = CountVectorizer(ngram_range=(1,3), binary=True, stop_words='english')#, max_features=2500\n",
    "words_like = cv_like.fit_transform(revs_like_df.text).todense()\n",
    "\n",
    "# use the counter option to get the most common words. \n",
    "# Count the most common tokens \n",
    "\n",
    "summaries = \"\".join(revs_like_df['text'])\n",
    "like_summaries = cv_like.build_analyzer()(summaries)\n",
    "like_vocab = Counter(like_summaries).most_common(40)\n",
    "like_vocab = pd.DataFrame(like_vocab)\n",
    "like_vocab.columns=['word','count']\n",
    "\n",
    "# find most commor words in revs from dis df \n",
    "\n",
    "cv_dis = CountVectorizer(ngram_range=(1,3), binary=True, stop_words='english')#, max_features=2500\n",
    "words_dis = cv_dis.fit_transform(revs_dis_df.text).todense()\n",
    "\n",
    "summaries = \"\".join(revs_dis_df['text'])\n",
    "dis_summaries = cv_dis.build_analyzer()(summaries)\n",
    "dis_vocab = Counter(dis_summaries).most_common(40)\n",
    "dis_vocab = pd.DataFrame(dis_vocab)\n",
    "dis_vocab.columns = ['word','count']\n",
    "\n",
    "# find which words are most common in like and dislike subsets\n",
    "# add them to a list to add to stop words\n",
    "\n",
    "revs_vocab = like_vocab.append(dis_vocab)\n",
    "revs_vocab.columns = ['word','count']\n",
    "rev_vocab = revs_vocab.groupby(['word'])[['count']].count()\n",
    "stop_noise = list(rev_vocab[rev_vocab['count'] == 2].index)\n",
    "\n",
    "# remove uni code\n",
    "\n",
    "def no_uni(value):\n",
    "    return value.decode('unicode_escape').encode('ascii','ignore')\n",
    "\n",
    "stop_noise=[no_uni(i) for i in stop_noise]\n",
    "\n",
    "# find the most common words over all \n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2), binary=True, stop_words='english')#max_features=2500\n",
    "words = cv.fit_transform(revs_df.text).todense()\n",
    "\n",
    "\n",
    "summaries = \"\".join(revs_df['text'])\n",
    "summaries = cv.build_analyzer()(summaries)\n",
    "vocab = Counter(summaries).most_common(40)\n",
    "vocab = pd.DataFrame(vocab)\n",
    "vocab.columns = ['word','count']\n",
    "\n",
    "# add to list and remove uni code\n",
    "\n",
    "stop_top = list(vocab['word'].values)\n",
    "stop_top = [no_uni(i) for i in stop_top]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
